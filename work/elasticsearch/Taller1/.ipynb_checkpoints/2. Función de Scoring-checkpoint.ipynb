{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2: Función de Scoring \n",
    "\n",
    "En esta práctica vamos a profundizar en el funcionamiento de scoring de las consultas de Eleasticsearch y como lo utiliza para asignar la relevancia de los documentos resultantes de una búsqueda.\n",
    "\n",
    "Puesto que es un concepto clave para entender correctamente la ordenación de los resultados de las consultas de Elasticsearch y una funcionalidad muy interesante para la implementación de buscadores sobre Elasticsearch, vamos a dedicarle el tiempo necesario para profundizar y entenderlo correctamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Función de puntuación\n",
    "\n",
    "Puesto que la base del scoring en Elasticserach es la función de puntuación que emplea para puntuar los diferentes resultados o match de la consulta, vamos a verla en detalle.\n",
    "\n",
    "Hasta la versión 2.0 de Eleasticsearch se tulizaba la clásica función de similaridad TF*IDF a partir de dicha versión utiliza una nueva función de similaridad llamada BM25 que también utiliza los conceptos de TF e IDF.\n",
    "\n",
    "La función de puntuación BM25 se define de la siguiente manera:\n",
    "\n",
    "<img src=\"../images/els/bm25_equation.png\" alt=\"index management\"/>\n",
    "\n",
    "Donde:\n",
    "1. **qi** es el i-esimo término de la consutla.\n",
    "2. **IDF(qi)** es la inversa de la frecuencia de documento del término i-esimo de la consulta.\n",
    "    * La función **IDF** evalúa la frecuencia con la que un término aparece en todos los documentos y penalíza los términos que son comunes.\n",
    "    * La fórmuna actual de BM25 es la siguiente:\n",
    "    <img src=\"../images/els/idf_equation.png\" alt=\"index management\"/>\n",
    "    \n",
    "        * **docCount** es el número de documentos que tienen un valor para el cámpo donde se está buscando el término.\n",
    "        * **f(qi)** es el número de documentos que contienene el término i-ésimo.\n",
    "3. **fieldLen/avgFieldLen** Intenta reflejar la relevancia de un término en para un campo:\n",
    "    * **fieldLen** es la logitud de un campo, es decir el número de términos que contiene.\n",
    "    * **avgFieldLen** es la longitud media de un campo teniendo en cuenta todos los documentos.\n",
    "    * Un campo que contenga menos términos se considera más relvante que un campo que tenga muchos términos. si un documento es más largo que la media, entoces el denominador crece, decreciendo la puntuación y si es más pequeño que la media, entonces el denominador se hace más pequeño, lo que hace incrementar la puntuación. \n",
    "    \n",
    "4. **Parámetro b en el denominador** Permite modificar la influencia de factor longitud del campo en el resultado. Por ejemplo, cuanto más aumente su valor, más se aplifica la influencia del factor de longitud. Si por el contrario se iguala a 0 el factor de longitud deja de tener relevancia en al puntuación.\n",
    "    * Su valor por defecto es de 0.75\n",
    "    \n",
    "5. **f(qi,D)** es el número de veces que aparece el término i-ésimo de la consulta en el documento D. Cuanta más veces apareza el término qi en el documento más relevante se considera y por tanto más puntuación tendrá.\n",
    "\n",
    "6. **k1** variable que nos permite indicar el grado de saturación para la fercuencia de un término:\n",
    "    * Nos ayuda a determinar como un único término puede afectar a la puntuación de un documento.\n",
    "    * El valor por defecto es de 1.2\n",
    "\n",
    "Podemos reformular la función anterior en términos de IDF y TF para un término de la siguiente forma:\n",
    "\n",
    "`\n",
    "score(qi) = IDF(qi) * TF(qi) \n",
    "`\n",
    "\n",
    "Donde:\n",
    "* **TF** es la frecuencia de un término i-ésimo del consulta q. Intenta reflejar la relevancia de un término dentro de un documento, es decir cuantas más apariciones de un término en un documento, más relevante se considera el documento.\n",
    "* **IDF** calcula la inversa de la fecuencia de documento del término i-esimo de la consulta q. Intenta reflejar la relevancia del término sobre el conjunto de todos los documentos. Un término se considera menos relevante si aparece en muchos documentos del índcie. \n",
    "\n",
    "### Boosting\n",
    "\n",
    "Podemos influir en el resultado de la función de puntuación potenciando su valor por medio de la técnica boosting. Consiste en dar un factor de multiplicación al resultado de la función de puntuación en función de si el término a buscar se encontrón en un índcie en concreto o en un campo en concreto. Por lo que la función de puntuación la prodríamos reformular de la siguiente forma:\n",
    "\n",
    "`\n",
    "score(qi) = IDF(qi) * TF(qi) * Boost\n",
    "`\n",
    "\n",
    "1. Boosting de índcie, tanto a la hora de crear un índice como a la hora de consultarlo, podemos hacer que los documentos provenientes de un indice tengan más relevancia (puntuación) en relación a otros índices potenciando dicho índice. Para ello indicaremos un valor de boost para dicho índicie. Es útil cuando realizamos consultas sobre varios índcies y queremos indicar que es más relevanta para el caso de uso los resultados provinientes de un o varios índcies en concreto.\n",
    "2. Boosting de campo, tanto a la hora de crear un índice como a la hora de consultarlo, podemos modificar el resultao de la puntución indicando que la puntución sea mayor para las ocurrencias de un término en un determinado campo de un documento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Función de puntuación en la practica\n",
    "\n",
    "Vamos a poner todos los conceptos vistos en el apartado anterior y para ver como se comporta la función de scoring vamos a utlizar el método explain de la API de elasticserch, que nos indicará el valor para cada uno de los valores de la función de scoring.\n",
    "\n",
    "Pero para poder ver como funciona en la práctica, primero tendermos que crear un índice e indexar unos cuantos datos en él. \n",
    "Vamos a crear un índice con el top de las 250 pelícumas con mayor puntuación en IMDB. El conjunto de datos que vamos a indexar lo puedes encontrar en la carpeta \"./work/data/elasticsearch/imdb_top_films/imdbTop250.csv\". Para indexarlo vamos a utilizar la función de importación de Kibana.\n",
    "\n",
    "Entramos en el menú  Analytics > Machine Learning > Data Visualizer. En la página dentro de la opción \"Visualize data from a file\" clicamos en el botón \"Select File\"\n",
    "\n",
    "<img src=\"../images/els/dataVisualizer.png\" alt=\"index management\"/>\n",
    "\n",
    "Seleccionamos o soltamos el fichero imdbTop250.csv sobre el icono de selección de archivo:\n",
    "\n",
    "<img src=\"../images/els/selecFileImportData.png\" alt=\"index management\"/>\n",
    "\n",
    "Cuando haya terminado de analizar el fichero veremos una página resumen del análisis, una muestra del fichero y una pequeña descripción del contenido de los diferentes campos. En este caso, como el fichero tiene cabecera, elasticserch es capaz de asignarle nombre a los campos.\n",
    "\n",
    "Clicamos en importar en el botón de abajo a la izquierda. Nos aparecera una nueva ventana pidíendonos cierta infromación para crear el índice. Seleccionamos la pestaña \"advanced\" e indicamos el nombre del índice a crear \"top_films\" y en el apartado \"index settings\" le indicamos que queremos que genere 4 shards. \n",
    "\n",
    "<img src=\"../images/els/importSettings.png\" alt=\"index management\"/>\n",
    "\n",
    "Clicamos en \"import\" y en unos minutos tendremos el índice creado y los documentos indexados.\n",
    "\n",
    "#### Ejercicio 1: \n",
    "\n",
    "* Consulta el mapping que elasticsearch ha creado para el índice de la importación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Consultar la información del scoring para una consulta\n",
    "\n",
    "Para obtener la información de como se ha generado el scoring para una consulta vamos a utilizar la petición \"_explain\" de la API de elasticsearch. Para utilizar esta petición y puesto que el scoring se calcula para cada documento, necesitamos indicarle el \"_id\" del documento para el que vamos a evaluar su puntuación. Por lo que antes de nada vamos a buscar la película \"Life of Brian\" para buscar el \"_id\" de documento del rating de la película para un año cualquiera.\n",
    "\n",
    "`\n",
    "POST top_films/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"Title\": \"Life of Brian\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "`\n",
    "\n",
    "Toma el \"_id\" del primer documento que aparezca. En mi caso es el siguiente documento:\n",
    "\n",
    "`\n",
    "{\n",
    "    \"_index\": \"top_films\",\n",
    "    \"_id\": \"Jgr6vYMB6aKWYvXtXaTl\",\n",
    "    \"_score\": 12.493233,\n",
    "    \"_source\": {\n",
    "      \"RunTime\": 94,\n",
    "      \"IMDByear\": 1999,\n",
    "      \"Rating\": 8.1,\n",
    "      \"Director\": \"Terry Jones\",\n",
    "      \"Cast4\": \"  Terry Gilliam\",\n",
    "      \"Title\": \"Life of Brian\",\n",
    "      \"Cast3\": \"  Michael Palin\",\n",
    "      \"Date\": 1979,\n",
    "      \"Cast2\": \"  John Cleese\",\n",
    "      \"IMDBlink\": \"/title/tt0079470/\",\n",
    "      \"Cast1\": \" Graham Chapman\",\n",
    "      \"Score\": 77,\n",
    "      \"Ranking\": 211,\n",
    "      \"Votes\": 387536,\n",
    "      \"Gross\": 20.05,\n",
    "      \"Genre\": \"Comedy\"\n",
    "    }\n",
    "}\n",
    "`\n",
    "\n",
    "Con el \"_id\" que has seleccionado, realiza la petición \"_explain\":\n",
    "\n",
    "`\n",
    "GET top_films/_explain/Jgr6vYMB6aKWYvXtXaTl\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"Title\": \"life\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "`\n",
    "\n",
    "En este caso la query que queremos evaluar es aquella que busca todos los documentos que contengan el término \"life\" en el campo \"Titulo\".\n",
    "\n",
    "En mi caso me devuelve la signiente información:\n",
    "\n",
    "`\n",
    "{\n",
    "  \"_index\": \"top_films\",\n",
    "  \"_id\": \"Jgr6vYMB6aKWYvXtXaTl\",\n",
    "  \"matched\": true,\n",
    "  \"explanation\": {\n",
    "    \"value\": 4.632488,\n",
    "    \"description\": \"weight(Title:life in 239) [PerFieldSimilarity], result of:\",\n",
    "    \"details\": [\n",
    "      {\n",
    "        \"value\": 4.632488,\n",
    "        \"description\": \"score(freq=1.0), computed as boost * idf * tf from:\",\n",
    "        \"details\": [\n",
    "          {\n",
    "            \"value\": 2.2,\n",
    "            \"description\": \"boost\",\n",
    "            \"details\": []\n",
    "          },\n",
    "          {\n",
    "            \"value\": 4.662221,\n",
    "            \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
    "            \"details\": [\n",
    "              {\n",
    "                \"value\": 15,\n",
    "                \"description\": \"n, number of documents containing term\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 1640,\n",
    "                \"description\": \"N, total number of documents with field\",\n",
    "                \"details\": []\n",
    "              }\n",
    "            ]\n",
    "          },\n",
    "          {\n",
    "            \"value\": 0.45164657,\n",
    "            \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
    "            \"details\": [\n",
    "              {\n",
    "                \"value\": 1,\n",
    "                \"description\": \"freq, occurrences of term within document\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 1.2,\n",
    "                \"description\": \"k1, term saturation parameter\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 0.75,\n",
    "                \"description\": \"b, length normalization parameter\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 3,\n",
    "                \"description\": \"dl, length of field\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 2.9536586,\n",
    "                \"description\": \"avgdl, average length of field\",\n",
    "                \"details\": []\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a verlo en detalle:\n",
    "\n",
    "Lo primero me indica el índice sobre el que se ha hecho la búsqueda y el _id del documento evaluado. También me indica que ha habido un match de ese documento para la consulta. Si no hay match no hay scoring:\n",
    "\n",
    "`\n",
    "  \"_index\": \"top_films\",\n",
    "  \"_id\": \"Jgr6vYMB6aKWYvXtXaTl\",\n",
    "  \"matched\": true,\n",
    "`\n",
    "\n",
    "El siguiente valor relevante es la puntuación obtenida para ese documento: \n",
    "\n",
    "`\"value\": 4.632488` \n",
    "\n",
    "y la descripción del scoring: \n",
    "\n",
    "`weight(Title:life in 239) [PerFieldSimilarity]`\n",
    "\n",
    "Al final entraremos en detalle del significado de esta descripción, primero vamos a ver como nos dice elasticsearch que se a calculado este valor.\n",
    "\n",
    "Primero nos indica la fórmula empleada para calcular el valor, la cual ya conocemos:\n",
    "\n",
    "`score(freq=1.0), computed as boost * idf * tf`\n",
    "\n",
    "Puesto que no hemos definido ningun boost para el índice ni para el campo \"Title\" por el que estamos buscando, elasticsearch utiliza su valor por defecto 2.2:\n",
    "\n",
    "`\n",
    "{\n",
    "    \"value\": 2.2,\n",
    "    \"description\": \"boost\",\n",
    "    \"details\": []\n",
    "},\n",
    "`\n",
    "\n",
    "A continuación nos explica como ha calculado el valor para idf y el valor obtendio\n",
    "\n",
    "`\n",
    "{\n",
    "    \"value\": 4.662221,\n",
    "    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
    "    \"details\": [\n",
    "      {\n",
    "        \"value\": 15,\n",
    "        \"description\": \"n, number of documents containing term\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 1640,\n",
    "        \"description\": \"N, total number of documents with field\",\n",
    "        \"details\": []\n",
    "      }\n",
    "    ]\n",
    "},\n",
    "`\n",
    "Para calcularlo nos dice que ha utilizado la siguiente función log(1 + (N - n + 0.5) / (n + 0.5)) donde n es el número de documentos que contiene el términos (15) y N es el total de documentos que tienen el campo \"Title\" (1640)\n",
    "\n",
    "Por último nos indica el valor para tf y cómo lo ha calculado:\n",
    "\n",
    "`\n",
    "{\n",
    "    \"value\": 0.45164657,\n",
    "    \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
    "    \"details\": [\n",
    "      {\n",
    "        \"value\": 1,\n",
    "        \"description\": \"freq, occurrences of term within document\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 1.2,\n",
    "        \"description\": \"k1, term saturation parameter\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 0.75,\n",
    "        \"description\": \"b, length normalization parameter\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 3,\n",
    "        \"description\": \"dl, length of field\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 2.9536586,\n",
    "        \"description\": \"avgdl, average length of field\",\n",
    "        \"details\": []\n",
    "      }\n",
    "    ]\n",
    "}\n",
    "`\n",
    "\n",
    "Para calcularlo ha utilizado la función que ya conocemos: freq / (freq + k1 * (1 - b + b * dl / avgdl)) donde: \n",
    "* freq es el número de ocurencias del término en el documento, en nuestro caso sólo aparece 1 vez.\n",
    "* k1 es el parametro de saturación del término que como no lo hemos modificado toma el valor por defecto 1.2\n",
    "* b es el valor de normalización de la longitud del campo que como no lo hemos modificado toma el valor por defecto 0.75.\n",
    "* dl es la longitud del campo en número de términos. En nuestro caso el valor del campo \"Title\" es \"Life of Brian\" por lo que su longitud es de 3 terminos.\n",
    "* avgdl es la media de longitud en términos del campo para todos los documentos indexados. En este caso 2.9536586. \n",
    "\n",
    "Hasta aquí todo correcto, pero vamos a entrar aun mas en detalle para entender los valores que nos ha devuelto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Sharding Effect\n",
    "\n",
    "Volvamos a los valores n y N con los que se calcularon el valor de idf. En nuestro caso el valor de N es 1640. Si consultamos en Kibana el número de documentos indexados veremos que el total asciende a 6500. ¿Qué ha pasado con el resto de documentos?\n",
    "\n",
    "En un principio podríamos pensar que esos documentos no tienen el campo \"Title\", pero como la importación la hemos hecho a partir de un csv, sabemos que ese campo existe en todos los documentos, por lo que el problema tiene que estar en otro sitio.\n",
    "\n",
    "Cuando le importamos los datos le indicamos a Kibana que crease un índcie con 4 shards. Vamos a ver que pasa si dividimos 6500 entre 4, el resultado es de 1.625 curiosamente próximo a 1640.\n",
    "\n",
    "Realicemos una consulta rápida:\n",
    "\n",
    "`\n",
    "GET /_cat/shards/top_films?v=true\n",
    "`\n",
    "\n",
    "En mi caso el resultado es el siguiente:\n",
    "\n",
    "<img src=\"../images/els/shardsScoring.png\" alt=\"index management\"/>\n",
    "\n",
    "Como podemos ver el shard 1 tiene justo el número de documentos que indica el valor N. De aquí podemos deducir dos cosas:\n",
    "\n",
    "* El documento está indexado en el shard 1.\n",
    "* Lo que es más importante para el calculo del scooring, sólo se está teniendo en cuenta los datos del shard donde se encuentra el documento para el que genera la puntuación.\n",
    "\n",
    "Esto es lo que se conoce con el \"Sharding Effect\". Cuando elasticsearch realiza una búsqieda hace un fanout de la query por todos los shards del índice y esta se ejecuta y evalúa en cada shard, ya que un shard es un índice de Lucene perfectamente funcional, devolviendo los 10 primeros _id de los documentos que machean la consulta **ordenados por su scoring**. Esto es lo que se llama la \"query phase\" de una consulta. Posteriormente cada shard devuelve la lista del resultado de evaluar la query en su índice al nodo orquestador que reordena estas listas de forma global y se devuelve el resultado final, lo que se conoce como la \"fetch phase\".\n",
    "\n",
    "¿Cómo podemos solucionar este problema?\n",
    "\n",
    "Cambiando el orden en el que se realiza la evaluación de los documentos utilizando el campo search_type en la búsqueda:\n",
    "* El valor por defecto \"search_type=query_then_fetch\" evalua localmente las frecuencias de los terminos.\n",
    "* El valor \"search_type=dfs_query_then_fetch\" permite calcular globalmente las frecuencias, pero aumenta la latencia de respuesta.\n",
    "    \n",
    "Vamos a ver como funciona para ejecutemos la consuta con la petición _sarch a la que le indicamos que utilice el search_type=dfs_query_then_fetch y además le pedimos que haga el explain:\n",
    "\n",
    "`\n",
    "POST top_films/_search?explain=true&pretty=true&search_type=dfs_query_then_fetch\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"Title\": \"life\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "`\n",
    "\n",
    "Para mi caso, en el resultado ya podemos ver como ha cambiado el resultado del score, en este caso el valor N ya si es igual a 6500:\n",
    "\n",
    "`\n",
    "\"_explanation\": {\n",
    "  \"value\": 4.28924,\n",
    "  \"description\": \"weight(Title:life in 75) [PerFieldSimilarity], result of:\",\n",
    "  \"details\": [\n",
    "    {\n",
    "      \"value\": 4.28924,\n",
    "      \"description\": \"score(freq=1.0), computed as boost * idf * tf from:\",\n",
    "      \"details\": [\n",
    "        {\n",
    "          \"value\": 2.2,\n",
    "          \"description\": \"boost\",\n",
    "          \"details\": []\n",
    "        },\n",
    "        {\n",
    "          \"value\": 4.3548646,\n",
    "          \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
    "          \"details\": [\n",
    "            {\n",
    "              \"value\": 83,\n",
    "              \"description\": \"n, number of documents containing term\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 6500,\n",
    "              \"description\": \"N, total number of documents with field\",\n",
    "              \"details\": []\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"value\": 0.44769573,\n",
    "          \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
    "          \"details\": [\n",
    "            {\n",
    "              \"value\": 1,\n",
    "              \"description\": \"freq, occurrences of term within document\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 1.2,\n",
    "              \"description\": \"k1, term saturation parameter\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 0.75,\n",
    "              \"description\": \"b, length normalization parameter\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 3,\n",
    "              \"description\": \"dl, length of field\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 2.8918462,\n",
    "              \"description\": \"avgdl, average length of field\",\n",
    "              \"details\": []\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. La influencia de los analizadores en la puntuación\n",
    "\n",
    "Como hemos visto, para calcular la puntuación se está evaluando constantemente las diferentes frecuencias para los términos, por lo que la forma en la que se extraen esos términos es fundamental para conseguir una buena ordenación por relevancia.\n",
    "\n",
    "* Utilizar el analizador del idioma en el que están escritos los textos de un documento ayudará a generar mejores términos y por tanto calcular con mayor precisión la puntución de los resultados de las consutlas.\n",
    "* Utilizar steamers que ayudan a mejorar el cálculo de las frecuencia de los términos al tener en cuenta los lexemas y raíces semánticas de los términos. \n",
    "* Usar listas de sinónimos ayudará a identificar terminos \"equivalentes\" lo que permitirá calcular con mayor precisión las frecuencias.\n",
    "* Definir correctos filtros para eliminar términos no relevantes o no tener en cuenta mayúsculas y minúsclas ayudan a eliminar ruido en el cálculo de la relevancia.\n",
    "* No solo definir analizadores a la hora de indexar los documentos, sino también a la hora de analizar los términos de la consulta que queremos realizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
