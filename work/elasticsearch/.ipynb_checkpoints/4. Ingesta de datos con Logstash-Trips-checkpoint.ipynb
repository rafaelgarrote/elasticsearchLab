{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesta de datos con Logstash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true}"
     ]
    }
   ],
   "source": [
    "!curl -X PUT http://elasticsearch:9200/_index_template/trips -H 'Content-Type: application/json' -d ' \\\n",
    "{ \\\n",
    "  \"index_patterns\": [\"trips\"], \\\n",
    "  \"template\": { \\\n",
    "    \"mappings\": { \\\n",
    "      \"dynamic_templates\": [ \\\n",
    "        { \\\n",
    "          \"strings_as_keywords\": { \\\n",
    "            \"match_mapping_type\": \"string\", \\\n",
    "            \"mapping\": { \"type\": \"keyword\" } \\\n",
    "          } \\\n",
    "        } \\\n",
    "      ], \\\n",
    "      \"properties\": { \\\n",
    "        \"EndAirportGeo\": { \"type\": \"geo_point\" }, \\\n",
    "        \"StartAirportGeo\": { \"type\": \"geo_point\" }, \\\n",
    "        \"DistanceKM\": { \"type\": \"integer\" }, \\\n",
    "        \"ActivityCostAUD\": { \"type\": \"integer\" }, \\\n",
    "        \"StartTime\": { \\\n",
    "          \"type\":   \"date\", \\\n",
    "          \"format\": \"HH:mm:ss||H:mm:ss\" \\\n",
    "        }, \\\n",
    "        \"EndTime\": { \\\n",
    "          \"type\":   \"date\", \\\n",
    "          \"format\": \"HH:mm:ss||H:mm:ss\" \\\n",
    "        }, \\\n",
    "        \"StartDate\": { \\\n",
    "          \"type\":   \"date\", \\\n",
    "          \"format\": \"dd/MM/yy\" \\\n",
    "        }, \\\n",
    "        \"EndDate\": { \\\n",
    "          \"type\":   \"date\", \\\n",
    "          \"format\": \"dd/MM/yy\" \\\n",
    "        } \\\n",
    "      } \\\n",
    "    } \\\n",
    "  } \\\n",
    "}'      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver el contenido del fichero de trips.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartAirport        object\n",
      "EndAirport          object\n",
      "TripID               int64\n",
      "Type                object\n",
      "ActivityID           int64\n",
      "ActivityCostAUD    float64\n",
      "AirlineCode         object\n",
      "Aircraft            object\n",
      "ServiceClass        object\n",
      "FlightNumber         int64\n",
      "StartCountry        object\n",
      "StartCityName       object\n",
      "StartLat           float64\n",
      "StartLong          float64\n",
      "StartDate           object\n",
      "StartTime           object\n",
      "EndCountry          object\n",
      "EndCityName         object\n",
      "EndLat             float64\n",
      "EndLong            float64\n",
      "EndDate             object\n",
      "EndTime             object\n",
      "Stops               object\n",
      "DistanceKM           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trips = pd.read_csv('../data/elasticsearch/tirps/trips.csv')\n",
    "\n",
    "print(trips.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StartAirport EndAirport     TripID Type  ActivityID  ActivityCostAUD  \\\n",
      "0          CBR        MEL  306007947  Air  1141935494          1241.36   \n",
      "1          MEL        CBR  306007947  Air  1141935494          1241.36   \n",
      "2          SYD        MEL  305316367  Air  1140039658           502.00   \n",
      "3          CBR        SYD  305312206  Air  1140385947          1313.16   \n",
      "4          MEL        SYD  305312206  Air  1140269701           350.00   \n",
      "\n",
      "  AirlineCode                                         Aircraft ServiceClass  \\\n",
      "0          QF         Boeing 737-800 (winglets) Passenger/BBJ2      Economy   \n",
      "1          QF                                   Boeing 717-200      Economy   \n",
      "2          VA         Boeing 737-800 (winglets) Passenger/BBJ2      Economy   \n",
      "3          QF  De Havilland (Bombardier) DHC-8-300 Dash 8 / 8Q      Economy   \n",
      "4          VA         Boeing 737-800 (winglets) Passenger/BBJ2      Economy   \n",
      "\n",
      "   FlightNumber     ...     StartDate StartTime  EndCountry  EndCityName  \\\n",
      "0           867     ...       23/4/21  17:35:00          AU    Melbourne   \n",
      "1          1516     ...       20/4/21  10:10:00          AU     Canberra   \n",
      "2           882     ...       21/3/21  19:00:00          AU    Melbourne   \n",
      "3          1444     ...       18/3/21  17:00:00          AU       Sydney   \n",
      "4           827     ...       17/3/21   9:00:00          AU       Sydney   \n",
      "\n",
      "      EndLat     EndLong  EndDate   EndTime    Stops  DistanceKM  \n",
      "0 -37.673295  144.843013  23/4/21  18:45:00  nonstop         468  \n",
      "1 -35.307350  149.190528  20/4/21  11:15:00  nonstop         468  \n",
      "2 -37.673295  144.843013  21/3/21  20:35:00  nonstop         705  \n",
      "3 -33.932922  151.179898  18/3/21  17:55:00  nonstop         235  \n",
      "4 -33.932922  151.179898  17/3/21  10:25:00  nonstop         705  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(trips.head(5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuración de logstash:\n",
    "\n",
    "`\n",
    "input {\n",
    "    file {\n",
    "        path => \"/tmp/data/*\"\n",
    "    }\n",
    "}\n",
    "\n",
    "filter {\n",
    "    csv {\n",
    "        source => \"message\"\n",
    "        columns => [\"StartAirport\",\"EndAirport\",\"TripID\",\"Type\",\"ActivityID\",\"ActivityCostAUD\",\"AirlineCode\",\"Aircraft\",\"ServiceClass\",\"FlightNumber\",\"StartCountry\",\"StartCityName\",\"StartLat\",\"StartLong\",\"StartDate\",\"StartTime\",\"EndCountry\",\"EndCityName\",\"EndLat\",\"EndLong\",\"EndDate\",\"EndTime\",\"Stops\",\"DistanceKM\"]\n",
    "        skip_header => true\n",
    "    }\n",
    "\n",
    "    mutate {\n",
    "        add_field => {\n",
    "            \"StartAirportGeo\" => \"%{StartLat},%{StartLong}\"\n",
    "            \"EndAirportGeo\" => \"%{EndLat},%{EndLong}\"\n",
    "            }\n",
    "        remove_field => [\"host\", \"@version\", \"@timestamp\", \"message\", \"StartLat\", \"EndLat\", \"StartLong\", \"EndLong\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "output {\n",
    "    elasticsearch {\n",
    "    hosts => \"elasticsearch:9200\"\n",
    "    index => \"trips\"\n",
    "  } \n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run --rm -it --network=datahack-nosql_default \\\n",
    "    -v /Users/rgarrote/desarrollo/datahack-nosql/work/data/elasticsearch/trips/pipeline/:/usr/share/logstash/pipeline/ \\\n",
    "    -v /Users/rgarrote/desarrollo/datahack-nosql/work/data/elasticsearch/trips/data/:/tmp/data/ \\\n",
    "docker.elastic.co/logstash/logstash:8.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creamos el data vaiew de los datos\n",
    "\n",
    "A fundamental aspect of starting to work with a dataset on Kibana is configuring the data view for the data. A Kibana data view determines what underlying Elasticsearch indices will be addressed in a given query, dashboard, alert, or machine learning job configuration. Data views also cache some metadata for underlying Elasticsearch indices, including the field names and data types (the schema) in a given group of indices. This cached data is used in the Kibana interface when creating and working with visualizations.\n",
    "\n",
    "In the case of time series data, data view can configure the name of the field containing the timestamp in a given index. This allows Kibana to narrow down your queries, dashboards, and so on to the appropriate time range on the underlying indices, allowing for fast and efficient results. The universal date and time picker at the top right of the screen allows granular control of time ranges. The time picker will not be available if a time field is not configured for a data view.\n",
    "Data view can also specify how fields should be formatted and rendered on visualizations. For example, a source.bytes integer field can be represented by bytes to automatically format values in human-readable units such as MB or GB.\n",
    "\n",
    "Para ello entramos en Kibana: http://127.0.0.1:5601\n",
    "\n",
    "A continuación entramos en la sección de Stack Management:\n",
    "Menu > Management > Stack Management\n",
    "\n",
    "Stack Management is home to UIs for managing all things Elastic Stack— indices, clusters, licenses, UI settings, data views, spaces, and more.\n",
    "\n",
    "Para crear nuestro data view accedemos a las sección de gestión de data views: \n",
    "Kibana > Data Views\n",
    "\n",
    "En esta página encontramos el listado de los Data Views ya creados. Para crear nuestro primer data view clickamos en el botón Create Data View.\n",
    "\n",
    "Para crear el Data View, es necesario indicar el índice o índices que van a ser la fuente de datos de esta data view. Para ello podemos indicar o bien el nombre del índice sobre el que crear el Data View o en el caso de querer crear el Data View sobre varios índices el patrón o expresión regular que tiene que cumplirse sobre el nombre de los índices.\n",
    "\n",
    "En nuestro caso vamos a utilizar el índice que hemos creado antes en la ingesta de datos, por lo que en el campo name introducimos el nombre del índice: trips.\n",
    "\n",
    "Puesto que el data set que hemos ingestado representa una serie de eventos en el tiempo, es por tanto una serie temporal, podemos indicar cual es el campo de tipo fecha que almacena esta información temporal introduciendo en el campo Timestamp field el campo StartDate. \n",
    "\n",
    "Una vez informado correctamente el formulario clickcamos en Create Data View.\n",
    "\n",
    "La pagina que nos muestra a continuación contiene la información del Data View que hemos creado, donde podemos ver todos los campos de nuestro data view y su información.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
