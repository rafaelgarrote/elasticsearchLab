{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Función de Scoring \n",
    "\n",
    "En esta práctica vamos a profundizar en el funcionamiento de scoring de las consultas de Eleasticsearch y como lo utiliza para asignar la relevancia de los documentos resultantes de una búsqueda.\n",
    "\n",
    "Puesto que es un concepto clave para entender correctamente la ordenación de los resultados de las consultas de Elasticsearch y una funcionalidad muy interesante para la implementación de buscadores sobre Elasticsearch, vamos a dedicarle el tiempo necesario para profundizar y entenderlo correctamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Función de puntuación\n",
    "\n",
    "Puesto que la base del scoring en Elasticserach es la función de puntuación que emplea para puntuar los diferentes resultados o match de la consulta, vamos a verla en detalle.\n",
    "\n",
    "Hasta la versión 2.0 de Eleasticsearch se tulizaba la clásica función de similaridad TF*IDF a partir de dicha versión utiliza una nueva función de similaridad llamada BM25 que también utiliza los conceptos de TF e IDF.\n",
    "\n",
    "La función de puntuación BM25 se define de la siguiente manera:\n",
    "\n",
    "<img src=\"../../images/els/bm25_equation.png\" alt=\"index management\"/>\n",
    "\n",
    "Donde:\n",
    "1. **qi** es el i-esimo término de la consutla.\n",
    "2. **IDF(qi)** es la inversa de la frecuencia de documento del término i-esimo de la consulta.\n",
    "    * La función **IDF** evalúa la frecuencia con la que un término aparece en todos los documentos y penalíza los términos que son comunes.\n",
    "    * La fórmuna actual de BM25 es la siguiente:\n",
    "    <img src=\"../../images/els/idf_equation.png\" alt=\"index management\"/>\n",
    "    \n",
    "        * **docCount** es el número de documentos que tienen un valor para el cámpo donde se está buscando el término.\n",
    "        * **f(qi)** es el número de documentos que contienene el término i-ésimo.\n",
    "3. **fieldLen/avgFieldLen** Intenta reflejar la relevancia de un término en para un campo:\n",
    "    * **fieldLen** es la logitud de un campo, es decir el número de términos que contiene.\n",
    "    * **avgFieldLen** es la longitud media de un campo teniendo en cuenta todos los documentos.\n",
    "    * Un campo que contenga menos términos se considera más relvante que un campo que tenga muchos términos. si un documento es más largo que la media, entoces el denominador crece, decreciendo la puntuación y si es más pequeño que la media, entonces el denominador se hace más pequeño, lo que hace incrementar la puntuación. \n",
    "    \n",
    "4. **Parámetro b en el denominador** Permite modificar la influencia de factor longitud del campo en el resultado. Por ejemplo, cuanto más aumente su valor, más se aplifica la influencia del factor de longitud. Si por el contrario se iguala a 0 el factor de longitud deja de tener relevancia en al puntuación.\n",
    "    * Su valor por defecto es de 0.75\n",
    "    \n",
    "5. **f(qi,D)** es el número de veces que aparece el término i-ésimo de la consulta en el documento D. Cuanta más veces apareza el término qi en el documento más relevante se considera y por tanto más puntuación tendrá.\n",
    "\n",
    "6. **k1** variable que nos permite indicar el grado de saturación para la fercuencia de un término:\n",
    "    * Nos ayuda a determinar como un único término puede afectar a la puntuación de un documento.\n",
    "    * El valor por defecto es de 1.2\n",
    "\n",
    "Podemos reformular la función anterior en términos de IDF y TF para un término de la siguiente forma:\n",
    "\n",
    "`\n",
    "score(qi) = IDF(qi) * TF(qi) \n",
    "`\n",
    "\n",
    "Donde:\n",
    "* **TF** es la frecuencia de un término i-ésimo del consulta q. Intenta reflejar la relevancia de un término dentro de un documento, es decir cuantas más apariciones de un término en un documento, más relevante se considera el documento.\n",
    "* **IDF** calcula la inversa de la fecuencia de documento del término i-esimo de la consulta q. Intenta reflejar la relevancia del término sobre el conjunto de todos los documentos. Un término se considera menos relevante si aparece en muchos documentos del índcie. \n",
    "\n",
    "### Boosting\n",
    "\n",
    "Podemos influir en el resultado de la función de puntuación potenciando su valor por medio de la técnica boosting. Consiste en dar un factor de multiplicación al resultado de la función de puntuación en función de si el término a buscar se encontrón en un índcie en concreto o en un campo en concreto. Por lo que la función de puntuación la prodríamos reformular de la siguiente forma:\n",
    "\n",
    "`\n",
    "score(qi) = IDF(qi) * TF(qi) * Boost\n",
    "`\n",
    "\n",
    "1. Boosting de índcie, tanto a la hora de crear un índice como a la hora de consultarlo, podemos hacer que los documentos provenientes de un indice tengan más relevancia (puntuación) en relación a otros índices potenciando dicho índice. Para ello indicaremos un valor de boost para dicho índicie. Es útil cuando realizamos consultas sobre varios índcies y queremos indicar que es más relevanta para el caso de uso los resultados provinientes de un o varios índcies en concreto.\n",
    "2. Boosting de campo, tanto a la hora de crear un índice como a la hora de consultarlo, podemos modificar el resultao de la puntución indicando que la puntución sea mayor para las ocurrencias de un término en un determinado campo de un documento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Función de puntuación en la practica\n",
    "\n",
    "Vamos a poner todos los conceptos vistos en el apartado anterior y para ver como se comporta la función de scoring vamos a utlizar el método explain de la API de elasticserch, que nos indicará el valor para cada uno de los valores de la función de scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Consultar la información del scoring para una consulta\n",
    "\n",
    "Para obtener la información de como se ha generado el scoring para una consulta vamos a utilizar la petición \"_explain\" de la API de elasticsearch. Para utilizar esta petición y puesto que el scoring se calcula para cada documento, necesitamos indicarle el \"_id\" del documento para el que vamos a evaluar su puntuación. Por lo que antes de nada vamos a buscar la receta con el título \"Hershey's \"Perfectly Chocolate\" Chocolate Cake\" para buscar el \"_id\" de documento.\n",
    "\n",
    "`\n",
    "POST recipes/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"\"\"Hershey's \"Perfectly Chocolate\" Chocolate Cake\"\"\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "`\n",
    "\n",
    "Toma el \"_id\" del primer documento que aparezca. En mi caso es el siguiente documento:\n",
    "\n",
    "`\n",
    "{\n",
    "        \"_index\": \"recipes\",\n",
    "        \"_id\": \"quawoIQBnF462_TnMdAZ\",\n",
    "        \"_score\": 4.618042,\n",
    "        \"_ignored\": [\n",
    "          \"event.original.keyword\"\n",
    "        ],\n",
    "        \"_source\": {\n",
    "          \"picture_link\": \"https://assets.epicurious.com/photos/58485cfe3b047eac0f3b347e/6:4/w_274%2Ch_169/Hershey%E2%80%99s-Perfectly-Chocolate-Chocolate-Cake-07122016-1.jpg\",\n",
    "          \"log\": {\n",
    "            \"file\": {\n",
    "              \"path\": \"/tmp/data/recipes.json\"\n",
    "            }\n",
    "          },\n",
    "          \"author\": \"The Hershey Company\",\n",
    "          \"url\": \"http://www.epicurious.com/recipes/food/views/hersheys-perfectly-chocolate-chocolate-cake\"\n",
    "}\n",
    "`\n",
    "\n",
    "Con el \"_id\" que has seleccionado, realiza la petición \"_explain\":\n",
    "\n",
    "`\n",
    "GET recipes/_explain/quawoIQBnF462_TnMdAZ\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"chocolate\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "`\n",
    "\n",
    "En este caso la query que queremos evaluar es aquella que busca todos los documentos que contengan el término \"chocolate\" en el campo \"title\".\n",
    "\n",
    "En mi caso me devuelve la signiente información:\n",
    "\n",
    "`\n",
    "{\n",
    "  \"_index\": \"recipes\",\n",
    "  \"_id\": \"quawoIQBnF462_TnMdAZ\",\n",
    "  \"matched\": true,\n",
    "  \"explanation\": {\n",
    "    \"value\": 4.618042,\n",
    "    \"description\": \"weight(title:chocolate in 680) [PerFieldSimilarity], result of:\",\n",
    "    \"details\": [\n",
    "      {\n",
    "        \"value\": 4.618042,\n",
    "        \"description\": \"score(freq=2.0), computed as boost * idf * tf from:\",\n",
    "        \"details\": [\n",
    "          {\n",
    "            \"value\": 2.2,\n",
    "            \"description\": \"boost\",\n",
    "            \"details\": []\n",
    "          },\n",
    "          {\n",
    "            \"value\": 3.3940127,\n",
    "            \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
    "            \"details\": [\n",
    "              {\n",
    "                \"value\": 74,\n",
    "                \"description\": \"n, number of documents containing term\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 2218,\n",
    "                \"description\": \"N, total number of documents with field\",\n",
    "                \"details\": []\n",
    "              }\n",
    "            ]\n",
    "          },\n",
    "          {\n",
    "            \"value\": 0.61847436,\n",
    "            \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
    "            \"details\": [\n",
    "              {\n",
    "                \"value\": 2,\n",
    "                \"description\": \"freq, occurrences of term within document\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 1.2,\n",
    "                \"description\": \"k1, term saturation parameter\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 0.75,\n",
    "                \"description\": \"b, length normalization parameter\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 5,\n",
    "                \"description\": \"dl, length of field\",\n",
    "                \"details\": []\n",
    "              },\n",
    "              {\n",
    "                \"value\": 4.8192067,\n",
    "                \"description\": \"avgdl, average length of field\",\n",
    "                \"details\": []\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a verlo en detalle:\n",
    "\n",
    "Lo primero me indica el índice sobre el que se ha hecho la búsqueda y el _id del documento evaluado. También me indica que ha habido un match de ese documento para la consulta. Si no hay match no hay scoring:\n",
    "\n",
    "`\n",
    "  \"_index\": \"recipes\",\n",
    "  \"_id\": \"quawoIQBnF462_TnMdAZ\",\n",
    "  \"matched\": true,\n",
    "`\n",
    "\n",
    "El siguiente valor relevante es la puntuación obtenida para ese documento: \n",
    "\n",
    "`\"value\": 4.618042` \n",
    "\n",
    "y la descripción del scoring: \n",
    "\n",
    "`weight(title:chocolate in 680) [PerFieldSimilarity]`\n",
    "\n",
    "Al final entraremos en detalle del significado de esta descripción, primero vamos a ver como nos dice elasticsearch que se a calculado este valor.\n",
    "\n",
    "Primero nos indica la fórmula empleada para calcular el valor, la cual ya conocemos:\n",
    "\n",
    "`score(freq=1.0), computed as boost * idf * tf`\n",
    "\n",
    "Puesto que no hemos definido ningun boost para el índice ni para el campo \"title\" por el que estamos buscando, elasticsearch utiliza su valor por defecto 2.2:\n",
    "\n",
    "`\n",
    "{\n",
    "    \"value\": 2.2,\n",
    "    \"description\": \"boost\",\n",
    "    \"details\": []\n",
    "},\n",
    "`\n",
    "\n",
    "A continuación nos explica como ha calculado el valor para idf y el valor obtendio\n",
    "\n",
    "`\n",
    "{\n",
    "    \"value\": 3.3940127,\n",
    "    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
    "    \"details\": [\n",
    "      {\n",
    "        \"value\": 74,\n",
    "        \"description\": \"n, number of documents containing term\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 2221,\n",
    "        \"description\": \"N, total number of documents with field\",\n",
    "        \"details\": []\n",
    "      }\n",
    "    ]\n",
    "},\n",
    "`\n",
    "Para calcularlo nos dice que ha utilizado la siguiente función log(1 + (N - n + 0.5) / (n + 0.5)) donde n es el número de documentos que contiene el términos (74) y N es el total de documentos que tienen el campo \"title\" (2221)\n",
    "\n",
    "Por último nos indica el valor para tf y cómo lo ha calculado:\n",
    "\n",
    "`\n",
    "{\n",
    "    \"value\": 0.61847436,\n",
    "    \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
    "    \"details\": [\n",
    "      {\n",
    "        \"value\": 2,\n",
    "        \"description\": \"freq, occurrences of term within document\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 1.2,\n",
    "        \"description\": \"k1, term saturation parameter\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 0.75,\n",
    "        \"description\": \"b, length normalization parameter\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 5,\n",
    "        \"description\": \"dl, length of field\",\n",
    "        \"details\": []\n",
    "      },\n",
    "      {\n",
    "        \"value\": 4.8192067,\n",
    "        \"description\": \"avgdl, average length of field\",\n",
    "        \"details\": []\n",
    "      }\n",
    "    ]\n",
    "}\n",
    "`\n",
    "\n",
    "Para calcularlo ha utilizado la función que ya conocemos: freq / (freq + k1 * (1 - b + b * dl / avgdl)) donde: \n",
    "* freq es el número de ocurencias del término en el documento, en nuestro caso aparece 2 veces.\n",
    "* k1 es el parametro de saturación del término que como no lo hemos modificado toma el valor por defecto 1.2\n",
    "* b es el valor de normalización de la longitud del campo que como no lo hemos modificado toma el valor por defecto 0.75.\n",
    "* dl es la longitud del campo en número de términos. En nuestro caso el valor del campo \"title\" es \"Hershey's \"Perfectly Chocolate\" Chocolate Cake\" por lo que su longitud es de 5 terminos.\n",
    "* avgdl es la media de longitud en términos del campo para todos los documentos indexados. En este caso 4.8192067. \n",
    "\n",
    "Hasta aquí todo correcto, pero vamos a entrar aun mas en detalle para entender los valores que nos ha devuelto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Sharding Effect\n",
    "\n",
    "Volvamos a los valores n y N con los que se calcularon el valor de idf. En nuestro caso el valor de N es 1640. Si consultamos en Kibana el número de documentos indexados veremos que el total asciende a 6500. ¿Qué ha pasado con el resto de documentos?\n",
    "\n",
    "En un principio podríamos pensar que esos documentos no tienen el campo \"Title\", pero como la importación la hemos hecho a partir de un csv, sabemos que ese campo existe en todos los documentos, por lo que el problema tiene que estar en otro sitio.\n",
    "\n",
    "Cuando le importamos los datos le indicamos a Kibana que crease un índcie con 4 shards. Vamos a ver que pasa si dividimos 6500 entre 4, el resultado es de 1.625 curiosamente próximo a 1640.\n",
    "\n",
    "Realicemos una consulta rápida:\n",
    "\n",
    "`\n",
    "GET /_cat/shards/recipes?v=true\n",
    "`\n",
    "\n",
    "En mi caso el resultado es el siguiente:\n",
    "\n",
    "<img src=\"../../images/els/index_shards_recipies.png\" alt=\"index management\"/>\n",
    "\n",
    "Como podemos ver el shard 0 tiene justo el número de documentos que indica el valor N. De aquí podemos deducir dos cosas:\n",
    "\n",
    "* El documento está indexado en el shard 0.\n",
    "* Lo que es más importante para el calculo del scooring, sólo se está teniendo en cuenta los datos del shard donde se encuentra el documento para el que genera la puntuación.\n",
    "\n",
    "Esto es lo que se conoce con el \"Sharding Effect\". Cuando elasticsearch realiza una búsqieda hace un fanout de la query por todos los shards del índice y esta se ejecuta y evalúa en cada shard, ya que un shard es un índice de Lucene perfectamente funcional, devolviendo los 10 primeros _id de los documentos que machean la consulta **ordenados por su scoring**. Esto es lo que se llama la \"query phase\" de una consulta. Posteriormente cada shard devuelve la lista del resultado de evaluar la query en su índice al nodo orquestador que reordena estas listas de forma global y se devuelve el resultado final, lo que se conoce como la \"fetch phase\".\n",
    "\n",
    "¿Cómo podemos solucionar este problema?\n",
    "\n",
    "Cambiando el orden en el que se realiza la evaluación de los documentos utilizando el campo search_type en la búsqueda:\n",
    "* El valor por defecto \"search_type=query_then_fetch\" evalua localmente las frecuencias de los terminos.\n",
    "* El valor \"search_type=dfs_query_then_fetch\" permite calcular globalmente las frecuencias, pero aumenta la latencia de respuesta.\n",
    "    \n",
    "Vamos a ver como funciona para ejecutemos la consuta con la petición _sarch a la que le indicamos que utilice el search_type=dfs_query_then_fetch y además le pedimos que haga el explain:\n",
    "\n",
    "`\n",
    "POST recipes/_search?explain=true&pretty=true&search_type=dfs_query_then_fetch\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"chocolate\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "`\n",
    "\n",
    "Para mi caso, en el resultado ya podemos ver como ha cambiado el resultado del score, en este caso el valor N ya si es igual a 6500:\n",
    "\n",
    "`\n",
    "\"_explanation\": {\n",
    "    \"value\": 4.414281,\n",
    "    \"description\": \"weight(title:chocolate in 590) [PerFieldSimilarity], result of:\",\n",
    "    \"details\": [\n",
    "    {\n",
    "      \"value\": 4.414281,\n",
    "      \"description\": \"score(freq=1.0), computed as boost * idf * tf from:\",\n",
    "      \"details\": [\n",
    "        {\n",
    "          \"value\": 2.2,\n",
    "          \"description\": \"boost\",\n",
    "          \"details\": []\n",
    "        },\n",
    "        {\n",
    "          \"value\": 3.364237,\n",
    "          \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
    "          \"details\": [\n",
    "            {\n",
    "              \"value\": 310,\n",
    "              \"description\": \"n, number of documents containing term\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 8976,\n",
    "              \"description\": \"N, total number of documents with field\",\n",
    "              \"details\": []\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"value\": 0.5964179,\n",
    "          \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
    "          \"details\": [\n",
    "            {\n",
    "              \"value\": 1,\n",
    "              \"description\": \"freq, occurrences of term within document\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 1.2,\n",
    "              \"description\": \"k1, term saturation parameter\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 0.75,\n",
    "              \"description\": \"b, length normalization parameter\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 2,\n",
    "              \"description\": \"dl, length of field\",\n",
    "              \"details\": []\n",
    "            },\n",
    "            {\n",
    "              \"value\": 4.7786317,\n",
    "              \"description\": \"avgdl, average length of field\",\n",
    "              \"details\": []\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. La influencia de los analizadores en la puntuación\n",
    "\n",
    "Como hemos visto, para calcular la puntuación se está evaluando constantemente las diferentes frecuencias para los términos, por lo que la forma en la que se extraen esos términos es fundamental para conseguir una buena ordenación por relevancia.\n",
    "\n",
    "* Utilizar el analizador del idioma en el que están escritos los textos de un documento ayudará a generar mejores términos y por tanto calcular con mayor precisión la puntución de los resultados de las consutlas.\n",
    "* Utilizar steamers que ayudan a mejorar el cálculo de las frecuencia de los términos al tener en cuenta los lexemas y raíces semánticas de los términos. \n",
    "* Usar listas de sinónimos ayudará a identificar terminos \"equivalentes\" lo que permitirá calcular con mayor precisión las frecuencias.\n",
    "* Definir correctos filtros para eliminar términos no relevantes o no tener en cuenta mayúsculas y minúsclas ayudan a eliminar ruido en el cálculo de la relevancia.\n",
    "* No solo definir analizadores a la hora de indexar los documentos, sino también a la hora de analizar los términos de la consulta que queremos realizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
