{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Ingesta de datos con Logstash\n",
    "\n",
    "En este ejercicio vamos a poner en práctica lo aprendido hasta haora:\n",
    "\n",
    "* Creación de index templates.\n",
    "* Ingesta de datos con Logstash.\n",
    "* Transformación y enriquecimiento de datos con Logstash.\n",
    "\n",
    "Para ello vamos a ingestar un conjunto de datos sobre vuelos de aviones comerciales, de esta forma prepararemos los datos que utilizaremos en próximos notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar vamos a familiarizarnos con los datos que quermos ingestar. Para ello vamos a ver el contenido del fichero que contiene el conjunto de datos fuente, trips.csv que puedes encontrar aquí: http://127.0.0.1:8889/edit/work/data/elasticsearch/trips/trips.csv\n",
    "\n",
    "Para explorar los datos, vamos a utilizar la librería pandas de python. Vemos que campos contiene y de que tipo son estos campos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../data/elasticsearch/tirps/trips.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-944124b5c8b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/elasticsearch/tirps/trips.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../data/elasticsearch/tirps/trips.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trips = pd.read_csv(\"../data/elasticsearch/tirps/trips.csv\")\n",
    "\n",
    "print(trips.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a mostrar una muestra de los cinco primeros registros para hacernos una idea de su contenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StartAirport EndAirport     TripID Type  ActivityID  ActivityCostAUD  \\\n",
      "0          CBR        MEL  306007947  Air  1141935494          1241.36   \n",
      "1          MEL        CBR  306007947  Air  1141935494          1241.36   \n",
      "2          SYD        MEL  305316367  Air  1140039658           502.00   \n",
      "3          CBR        SYD  305312206  Air  1140385947          1313.16   \n",
      "4          MEL        SYD  305312206  Air  1140269701           350.00   \n",
      "\n",
      "  AirlineCode                                         Aircraft ServiceClass  \\\n",
      "0          QF         Boeing 737-800 (winglets) Passenger/BBJ2      Economy   \n",
      "1          QF                                   Boeing 717-200      Economy   \n",
      "2          VA         Boeing 737-800 (winglets) Passenger/BBJ2      Economy   \n",
      "3          QF  De Havilland (Bombardier) DHC-8-300 Dash 8 / 8Q      Economy   \n",
      "4          VA         Boeing 737-800 (winglets) Passenger/BBJ2      Economy   \n",
      "\n",
      "   FlightNumber     ...     StartDate StartTime  EndCountry  EndCityName  \\\n",
      "0           867     ...       23/4/21  17:35:00          AU    Melbourne   \n",
      "1          1516     ...       20/4/21  10:10:00          AU     Canberra   \n",
      "2           882     ...       21/3/21  19:00:00          AU    Melbourne   \n",
      "3          1444     ...       18/3/21  17:00:00          AU       Sydney   \n",
      "4           827     ...       17/3/21   9:00:00          AU       Sydney   \n",
      "\n",
      "      EndLat     EndLong  EndDate   EndTime    Stops  DistanceKM  \n",
      "0 -37.673295  144.843013  23/4/21  18:45:00  nonstop         468  \n",
      "1 -35.307350  149.190528  20/4/21  11:15:00  nonstop         468  \n",
      "2 -37.673295  144.843013  21/3/21  20:35:00  nonstop         705  \n",
      "3 -33.932922  151.179898  18/3/21  17:55:00  nonstop         235  \n",
      "4 -33.932922  151.179898  17/3/21  10:25:00  nonstop         705  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(trips.head(5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Ceración del index template para modelar los datos \n",
    "\n",
    "Ahora que ya tenemos una idea de la información que queremos indexar, vamos a crear el modelo de datos que va a alojar la información según nuestras necesidades de explotación.\n",
    "\n",
    "Para ello crea un index template con nombre trips que cumpla las siguientes condiciones:\n",
    "\n",
    "* El template se aplicará para todos lo índices cuyo nombre se llame \"trips\".\n",
    "* Todos los campos de tipo string se almacenarán como tipo keyword. Sugerencia, utiliza una dynamic template para definir esta condición.\n",
    "* Los campos EndAirportGeo y StartAirportGeo que vamos a crear los vamos a almacenar con tipo geo_point para poder explotarlos correctamente utilizando consultas geo espaciales. En este enlace puedes ver como definir este tipo de datos: https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html\n",
    "* Los campos DistanceKM y ActivityCostAUD los almacenaremos como tipo integer para poder hacer agregaciones sobre ellos.\n",
    "* Los campos StartTime, EndTime serán de tipo date con formato horaio. Consultar los datos para comprobar que formatos hay que indicar al crear el campo. En este enlace puedes ver como definir el campo de tipo date: https://www.elastic.co/guide/en/elasticsearch/reference/current/date.html y en este otro como espedificar el formato de las fechas: https://www.elastic.co/guide/en/elasticsearch/reference/current/date.html#multiple-date-formats\n",
    "* Los campos StartDate y EndDate serán de tipo date con formato de fecha dia/mes/año. Consultar los datos para comprobar que formatos hay que indicar al crear el campo.\n",
    "\n",
    "Una vez creado, consulta en Kibana que todo se ha creado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true}"
     ]
    }
   ],
   "source": [
    "!curl -X PUT http://elasticsearch:9200/_index_template/trips -H 'Content-Type: application/json' -d ' \\\n",
    "{ \\\n",
    "  \"index_patterns\": [\"trips\"], \\\n",
    "  \"template\": { \\\n",
    "    \"mappings\": { \\\n",
    "      \"dynamic_templates\": [ \\\n",
    "        { \\\n",
    "          \"strings_as_keywords\": { \\\n",
    "            \"match_mapping_type\": \"string\", \\\n",
    "            \"mapping\": { \"type\": \"keyword\" } \\\n",
    "          } \\\n",
    "        } \\\n",
    "      ], \\\n",
    "      \"properties\": { \\\n",
    "        \"EndAirportGeo\": { \"type\": \"geo_point\" }, \\\n",
    "        \"StartAirportGeo\": { \"type\": \"geo_point\" }, \\\n",
    "        \"DistanceKM\": { \"type\": \"integer\" }, \\\n",
    "        \"ActivityCostAUD\": { \"type\": \"integer\" }, \\\n",
    "        \"StartTime\": { \\\n",
    "          \"type\":   \"date\", \\\n",
    "          \"format\": \"HH:mm:ss||H:mm:ss||HH:mm||H:mm\" \\\n",
    "        }, \\\n",
    "        \"EndTime\": { \\\n",
    "          \"type\":   \"date\", \\\n",
    "          \"format\": \"HH:mm:ss||H:mm:ss||HH:mm||H:mm\" \\\n",
    "        }, \\\n",
    "        \"StartDate\": { \\\n",
    "          \"type\":   \"date\", \\\n",
    "          \"format\": \"dd/MM/yy||dd/M/yy||d/MM/yy||d/M/yy\" \\\n",
    "        }, \\\n",
    "        \"EndDate\": { \\\n",
    "          \"type\":   \"date\", \\\n",
    "          \"format\": \"dd/MM/yy||dd/m/yy||d/MM/yy||d/M/yy\" \\\n",
    "        } \\\n",
    "      } \\\n",
    "    } \\\n",
    "  } \\\n",
    "}'      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Configurar la ingesta de datos en Logstahs\n",
    "\n",
    "Antes de levantar el servicio de Logstash es enecesario configurarlo. Para ello encontrarás dentro de la carpeta work/data/elasticsearch/trips/pipeline/ el fichero de configuración logstash-trips.conf editalo para modificar la configuración.\n",
    "\n",
    "* Primero añade el imput plugin, que será de tipo fichero y parseará los ficheros que encuentre en /tmp/data/. En este enlace tienes toda la documentación de como configurar este plugin: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html\n",
    "* Añade los filtros para realizar las siguientes operaciones con los datos:\n",
    "    * Indica que el origen es un fichero csv utilizando el csv plugin. En este enlace puedes encontrar como configurar este plugin: https://www.elastic.co/guide/en/logstash/current/plugins-filters-csv.html Indica que ignore el header y especifica cuales seran los nombres de las columnas: StartAirport\",\"EndAirport\",\"TripID\",\"Type\",\"ActivityID\",\"ActivityCostAUD\",\"AirlineCode\",\"Aircraft\",\"ServiceClass\",\"FlightNumber\",\"StartCountry\",\"StartCityName\",\"StartLat\",\"StartLong\",\"StartDate\",\"StartTime\",\"EndCountry\",\"EndCityName\",\"EndLat\",\"EndLong\",\"EndDate\",\"EndTime\",\"Stops\",\"DistanceKM\".\n",
    "    * Modifica los mensajes utilizando el plugin mutate (https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html) para añadir dos campos que vamos a calcular de la siguiente forma:\n",
    "        * StartAirportGeo será el resultado de concatenar StartLat y StartLong separados por una coma.\n",
    "        * EndAirportGeo será el resultado de concatenar EndLat y EndLong separados por una coma.\n",
    "    * Por último, con el mismo plugin mutate, elimina los siguientes campos del mensaje: \"host\", \"@version\", \"@timestamp\", \"message\", \"StartLat\", \"EndLat\", \"StartLong\", \"EndLong\".\n",
    "* Indica que los mensajes procesados se almacenarán en elasticsearch en el índice trips utilizando el plugin output de Elasticsearch: https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuración de logstash:\n",
    "\n",
    "`\n",
    "input {\n",
    "    file {\n",
    "        path => \"/tmp/data/*\"\n",
    "    }\n",
    "}\n",
    "`\n",
    "\n",
    "`\n",
    "filter {\n",
    "    csv {\n",
    "        source => \"message\"\n",
    "        columns => [\"StartAirport\",\"EndAirport\",\"TripID\",\"Type\",\"ActivityID\",\"ActivityCostAUD\",\"AirlineCode\",\"Aircraft\",\"ServiceClass\",\"FlightNumber\",\"StartCountry\",\"StartCityName\",\"StartLat\",\"StartLong\",\"StartDate\",\"StartTime\",\"EndCountry\",\"EndCityName\",\"EndLat\",\"EndLong\",\"EndDate\",\"EndTime\",\"Stops\",\"DistanceKM\"]\n",
    "        skip_header => true\n",
    "    }\n",
    "\n",
    "    mutate {\n",
    "        add_field => {\n",
    "            \"StartAirportGeo\" => \"%{StartLat},%{StartLong}\"\n",
    "            \"EndAirportGeo\" => \"%{EndLat},%{EndLong}\"\n",
    "            }\n",
    "        remove_field => [\"host\", \"@version\", \"@timestamp\", \"message\", \"StartLat\", \"EndLat\", \"StartLong\", \"EndLong\"]\n",
    "    }\n",
    "}\n",
    "`\n",
    "\n",
    "`\n",
    "output {\n",
    "    elasticsearch {\n",
    "    hosts => \"elasticsearch:9200\"\n",
    "    index => \"trips\"\n",
    "  } \n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio3: Levantar la imagen de docker de Logstash\n",
    "\n",
    "Una vez configurado, levanta la imagen de docker de logstash montando los volúmenes que contienen la configuración y la carpeta donde dejaremos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: docker: not found\r\n"
     ]
    }
   ],
   "source": [
    "docker run --rm -it --network=datahack-elastic-v1-clase_default \\\n",
    "    -v /Users/rgarrote/desarrollo/datahack-elastic-v1/work/ejercicios_resueltos/data/elasticsearch/trips/pipeline/:/usr/share/logstash/pipeline/ \\\n",
    "    -v /Users/rgarrote/desarrollo/datahack-elastic-v1/work/ejercicios_resueltos/data/elasticsearch/trips/data/:/tmp/data/ \\\n",
    "docker.elastic.co/logstash/logstash:8.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copia el fichero de trips que vimos al principo del notebook en la carpeta work/data/elasticsearch/trips/data/. Una vez que copies el fichero Logstash lo procesará e insertará los datos en el índice de Elasticsearch indicado en la configuración.\n",
    "\n",
    "* Entra en Kibana para comprobar que se ha creado correctamente el índice. Comprueba el mapping type.\n",
    "* ¿Cuántos documentos a insertado?\n",
    "* Realiza una consulta para mostrar 10 elementos insertados en el índice. Comprueba que el contenido de los campos creados son correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
